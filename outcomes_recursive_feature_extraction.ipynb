{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.path as path\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime, time\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sknn.mlp import Classifier, Layer\n",
    "from sklearn.linear_model import LinearRegression, RidgeClassifierCV, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.cross_validation import KFold, train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_data():\n",
    "df = pd.read_csv('train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.total_time.map(lambda x: np.log10(x+1)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_color = pd.DataFrame({'color1':df.Color.str.split('/').str[0], 'color2':df.Color.str.split('/').str[1]})\n",
    "vc_color = pd.concat((df_color['color1'], df_color['color2'])).value_counts()\n",
    "common_colors = vc_color[vc_color > 300].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_vars(df, cols_x, cols_y=None):\n",
    "    minmax = MinMaxScaler()\n",
    "    \n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.DateTime = pd.to_datetime(df.DateTime)\n",
    "    df['weekday'] = df.DateTime.dt.weekday\n",
    "    df['weekend'] = (df.weekday > 4) * 1\n",
    "    df['viralata'] = (df.Breed.str.contains('Mix') | df.Breed.str.contains('/')) *1\n",
    "    df['named'] = ~df.Name.isnull() * 1\n",
    "    df['common_colors'] = df.Color.isin(common_colors) * 1\n",
    "    df['sex'] = df.SexuponOutcome.str.split(' ').str[1]\n",
    "    df['castrado'] = (df.SexuponOutcome.str.split(' ').str[0].str.contains('Neutered') | df.SexuponOutcome.str.split(' ').str[0].str.contains('Spayed')) * 1\n",
    "    df['first_color'] = df.Color.str.split('/').str[0].str.split(' ').str[0]\n",
    "    df['raca'] = df.Breed.str.replace('Mix','').str.split('/').str[0].str.strip()\n",
    "    #     df.ix[df.AgeuponOutcome.isnull(),'AgeuponOutcome'] = 0\n",
    "    filt = df.AgeuponOutcome.str.contains('year')\n",
    "    df['days_multiplyer'] = 0\n",
    "    df.ix[df.AgeuponOutcome.str.contains('year')==True,'days_multiplyer'] = 365\n",
    "    df.ix[df.AgeuponOutcome.str.contains('month')==True,'days_multiplyer'] = 30\n",
    "    df.ix[df.AgeuponOutcome.str.contains('week')==True,'days_multiplyer'] = 7\n",
    "    df.ix[df.AgeuponOutcome.str.contains('day')==True,'days_multiplyer'] = 1\n",
    "    df.totaltime = df.AgeuponOutcome.str.split().str[0]\n",
    "    df.ix[df.totaltime.isnull(),'AgeuponOutcome'] = 0\n",
    "    df['total_time'] = df.totaltime.astype('float64') * df.days_multiplyer\n",
    "    \n",
    "    df.ix[df.total_time.isnull(), 'total_time'] = 0\n",
    "#     df.total_time = df.total_time.map(lambda x: np.log10(x+1))\n",
    "    df['mixed_color'] = df.Color.str.contains('/').astype('int')\n",
    "    \n",
    "    df['year'] = df.DateTime.dt.year\n",
    "    df['month'] = df.DateTime.dt.month\n",
    "    df['yearmonth'] = df.DateTime.dt.month + df.DateTime.dt.year\n",
    "    df['day'] = df.DateTime.dt.day\n",
    "    df['time'] = df.DateTime.dt.hour * 60 + df.DateTime.dt.minute\n",
    "#     df.time = df.time.map(lambda x: np.log10(x+1))\n",
    "    \n",
    "    df['name_len'] = df.Name.str.len()\n",
    "    df.ix[df.name_len.isnull(), 'name_len'] = df.name_len.median()\n",
    "    \n",
    "    X = pd.get_dummies(df[cols_x]).values\n",
    "    if cols_y:            \n",
    "        df.ix[df.OutcomeType == 'Return_to_owner', 'IndY'] = 1\n",
    "        df.ix[df.OutcomeType == 'Euthanasia', 'IndY'] = 2\n",
    "        df.ix[df.OutcomeType == 'Adoption', 'IndY'] = 3\n",
    "        df.ix[df.OutcomeType == 'Transfer', 'IndY'] = 4\n",
    "        df.ix[df.OutcomeType == 'Died', 'IndY'] = 5\n",
    "        df.sort_values(by='OutcomeType')        \n",
    "        return X, df[cols_y].values\n",
    "    else:\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.index = [df.index,df.Color]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.ix[df.mixed_color.isin(df.mixed_color.value_counts()[df.mixed_color.value_counts() == True].index)]['OutcomeType'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_x = [\n",
    "    'AnimalType','SexuponOutcome','viralata',\n",
    "    'total_time','weekday','weekend',\n",
    "    'common_colors','mixed_color',\n",
    "    'year', 'name_len', 'month', \n",
    "    'day', 'time','named',\n",
    "    'sex','castrado','first_color','raca']\n",
    "cols_y = ['OutcomeType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_1 = [\n",
    "    'AnimalType',\n",
    "    'viralata','weekend','total_time','time','name_len','year','month',\n",
    "    'named','sex','castrado','first_color','raca'\n",
    "]\n",
    "# cols_1 = ['common_colors','SexuponOutcome','mixed_color','AnimalType','viralata','weekend','year']\n",
    "cols_rf = ['total_time', 'SexuponOutcome', 'AnimalType']\n",
    "cols_extra = ['total_time','time', 'SexuponOutcome', 'AnimalType']\n",
    "cols_gb = ['total_time','time','name_len', 'month', 'AnimalType', 'SexuponOutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, Y = get_vars(df, cols_x, cols_y)\n",
    "X = pd.get_dummies(df[cols_1])\n",
    "gb_features = X.columns\n",
    "Y = Y.reshape(Y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.ix[df.total_time.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8909.666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(df.OutcomeType,n_folds=2, shuffle=True, random_state=500)\n",
    "# a = np.concatenate((list(kf)[0][0], list(kf)[1][0]))#, list(kf)[2][0], list(kf)[3][0]))\n",
    "a = list(kf)[0][0]#, list(kf)[2][0], list(kf)[3][0]))\n",
    "b = list(kf)[1][0]\n",
    "# c = list(list(kf)[2][0])[0:8909]\n",
    "# d = list(list(kf)[3][0])[0:6682]\n",
    "\n",
    "\n",
    "# X_knn = X[train]\n",
    "# Y_knn = Y[train]\n",
    "\n",
    "# X_gb = X[train]\n",
    "# Y_gb = Y[train]\n",
    "\n",
    "# X_forest = X[train]\n",
    "# Y_forest = Y[train]\n",
    "\n",
    "# X_test = X[test]\n",
    "# Y_test = Y[test]\n",
    "\n",
    "# df_knn = df.ix[train]\n",
    "# df_gb = df.ix[train]\n",
    "# df_forest = df.ix[train]\n",
    "\n",
    "# df_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_x = X_train\n",
    "# train_y = Y_train\n",
    "# test_x = X_test\n",
    "# test_y = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_regression(forest, train_x, train_y, test_x=None, test_y=None):\n",
    "    nfolds = 5\n",
    "    ini = datetime.now()\n",
    "\n",
    "    kf = StratifiedKFold(train_y, n_folds=nfolds, shuffle=True, random_state=500)\n",
    "    log_acc = 0\n",
    "    print('Training linear...')\n",
    "    for k, (train, test) in enumerate(kf, start=1):\n",
    "        forest.fit(train_x[train], train_y[train])\n",
    "        pred = forest.predict(train_x[test]) \n",
    "        del pred\n",
    "        \n",
    "#     log_acc = 0\n",
    "#     print('Training ridge...')\n",
    "#     forest.fit(train_x, train_y)\n",
    "#     pred = forest.predict(train_x) \n",
    "#     del pred\n",
    "    \n",
    "    fim = datetime.now()\n",
    "    print(fim - ini)\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_classifier(forest, train_x, train_y, nfolds, test_x=None, test_y=None):\n",
    "    ini = datetime.now()\n",
    "\n",
    "    kf = StratifiedKFold(train_y, n_folds=nfolds, shuffle=True)\n",
    "#     log_acc = 0\n",
    "    print('Training classifier...')\n",
    "    for k, (train, test) in enumerate(kf, start=1):\n",
    "        forest.fit(train_x[train], train_y[train])\n",
    "        print(k, ' ', end=\"\")\n",
    "#         pred = forest.predict_proba(train_x[test])\n",
    "        \n",
    "#         loglo = log_loss(train_y[test], pred)\n",
    "#         log_acc += loglo\n",
    "#         print('fold:', k, 'log loss:', loglo)\n",
    "#         del pred\n",
    "        \n",
    "        \n",
    "    scores = cross_validation.cross_val_score(forest, train_x, train_y, cv=5, scoring='log_loss')\n",
    "    print(\"Log loss: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "    \n",
    "    \n",
    "#     print('acc:',log_acc/nfolds)\n",
    "#     forest.fit(train_x, train_y)\n",
    "#     print('final log loss: ',log_loss(train_y, forest.predict_proba(train_x)))\n",
    "#     print('\\n\\n')\n",
    "#     log_acc = 0\n",
    "#     print('Training rf...')\n",
    "#     forest.fit(train_x, train_y)\n",
    "#     pred = forest.predict_proba(train_x) \n",
    "#     loglo = log_loss(train_y, pred)\n",
    "#     log_acc += loglo\n",
    "#     print('log loss:', loglo)\n",
    "#     del pred\n",
    "\n",
    "    fim = datetime.now()\n",
    "    print(fim - ini)\n",
    "    print('')\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minmax1 = MinMaxScaler()\n",
    "# minmax1 = minmax1.fit(pd.get_dummies(df[cols_1]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# minmax4 = MinMaxScaler()\n",
    "# minmax4 = minmax4.fit(pd.get_dummies(df[cols_4]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(x, y, y_ind):    \n",
    "    x1 = x\n",
    "    #y=y[a]\n",
    "#     x4 = pd.get_dummies(x[cols_4]).values\n",
    "#     x1_minmax = minmax1.transform(x1)\n",
    "#     x4_minmax = minmax4.transform(x4)\n",
    "    x1_log2 = np.log2(x1+1)\n",
    "    #x1_log10 = np.log10(x1+1)\n",
    "    \n",
    "#     xrf = pd.get_dummies(x[cols_rf]).values\n",
    "#     xrf = np.log2(xrf+1)\n",
    "#     xextra = pd.get_dummies(x[cols_extra]).values\n",
    "#     xextra = np.log10(xextra+1)\n",
    "#     xgb = pd.get_dummies(x[cols_gb]).values\n",
    "        \n",
    "    if type(rf_features) != type(None):  \n",
    "        xrf = pd.get_dummies(x)[rf_features].values[a]\n",
    "        print('new rf')\n",
    "    else:\n",
    "        xrf = x1\n",
    "    xrf = np.log2(xrf+1)\n",
    "    \n",
    "    if type(extra_features) != type(None):        \n",
    "        xextra = pd.get_dummies(x)[extra_features].values[a]\n",
    "        print('new extra')\n",
    "    else:\n",
    "        xextra = x1\n",
    "    xextra = np.log10(xextra+1)\n",
    "    \n",
    "    if type(gb_features) != type(None):\n",
    "        xgb = pd.get_dummies(x)[gb_features].values\n",
    "        print('new gb')\n",
    "    else:\n",
    "        xgb = x1\n",
    "    \n",
    "    \n",
    "    nfolds = 2\n",
    "#     kf = StratifiedKFold(y, n_folds=nfolds, shuffle=True)\n",
    "    \n",
    "    extra = ExtraTreesClassifier(n_estimators=400, max_depth=50,max_leaf_nodes=60, n_jobs=4, random_state=500)    \n",
    "    \n",
    "    rf_gini = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=75,\n",
    "        max_leaf_nodes=40,\n",
    "        n_jobs=4,\n",
    "        random_state=500,\n",
    "        criterion='gini')\n",
    "        \n",
    "    x1_log10 = np.log10(x.values[a]+1)\n",
    "    knn = KNeighborsClassifier(500)\n",
    "    gb = GradientBoostingClassifier(min_samples_split=1000, max_depth=6, random_state=500)\n",
    "    \n",
    "#     for k, (train, test) in enumerate(kf, start=1):\n",
    "        \n",
    "    #extra = train_classifier(extra, xextra, y, 5)\n",
    "#         ens = gb1.predict_proba(x1_minmax[train])\n",
    "#         ens = np.concatenate((x1_minmax[train], ens), axis=1)\n",
    "\n",
    "    #rf_gini = train_classifier(rf_gini, xrf, y, 10)\n",
    "#     rf_entropy = train_classifier(rf_entropy, x1_log2, y, 10)\n",
    "    \n",
    "#         ens = gb1.predict_proba(x1_minmax[train])\n",
    "#         ens = np.concatenate((x1_minmax[train], ens), axis=1)\n",
    "\n",
    "    #knn = train_classifier(knn, x1_log10, y, 4)\n",
    "#         ens = gb1.predict_proba(x1_minmax[train])\n",
    "#         ens = np.concatenate((x1_minmax[train], ens), axis=1)\n",
    "\n",
    "#         ridge = RidgeClassifierCV()\n",
    "#         ridge = train_regression(ridge, x1_minmax[train], y[train])\n",
    "#         ens = ens.reshape(ens.shape[0],1)\n",
    "\n",
    "#         ens = np.concatenate((x1_minmax[train], ens), axis=1)\n",
    "    gb = train_classifier(gb, xgb, y, 5)\n",
    "    print('\\n')\n",
    "#     pass\n",
    "    \n",
    "            \n",
    "\n",
    "#     gb = train_gb(np.concatenate((ens1, ens2, x4),axis=1), y)\n",
    "\n",
    "    #         proba = gb.predict_proba(np.concatenate((ens, X[train]),axis=1))\n",
    "        \n",
    "#     return extra, rf_gini, knn, gb\n",
    "\n",
    "\n",
    "    return extra, rf_gini, knn, gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pred(extra, rf, knn, gb, x):\n",
    "    x1 = x.values[a]\n",
    "#     x4 = pd.get_dummies(x[cols_4]).values\n",
    "    \n",
    "#     x1_minmax = minmax1.transform(x1)\n",
    "#     x4_minmax = minmax4.transform(x4)\n",
    "#     x1_log2 = np.log2(x1+1)\n",
    "    x1_log10 = np.log10(x1+1)   \n",
    "    \n",
    "    if type(rf_features) != type(None):  \n",
    "        xrf = pd.get_dummies(x)[rf_features].values[a]\n",
    "        print('new rf')\n",
    "    else:\n",
    "        xrf = x1\n",
    "#     xrf = np.log2(xrf+1)\n",
    "    \n",
    "    if type(extra_features) != type(None):        \n",
    "        xextra = pd.get_dummies(x)[extra_features].values[a]\n",
    "        print('new extra')\n",
    "    else:\n",
    "        xextra = x1\n",
    "#     xextra = np.log10(xextra+1)\n",
    "    \n",
    "    if type(gb_features) != type(None):\n",
    "        xgb = pd.get_dummies(x)[gb_features].values[a]\n",
    "        print('new gb')\n",
    "    else:\n",
    "        xgb = x1\n",
    "    \n",
    "    \n",
    "    one = extra.predict_proba(xextra)\n",
    "    two = rf.predict_proba(xrf)\n",
    "    three = knn.predict_proba(x1_log10)\n",
    "#     ens = ens.reshape(ens.shape[0],1)\n",
    "#     ens = np.concatenate((x4, ens), axis=1)\n",
    "    four = gb.predict_proba(xgb)\n",
    "#     return gb.predict_proba(ens)\n",
    "    newx = [one, two, three, four]\n",
    "    return newx\n",
    "#     return gb.predict_proba(np.concatenate((ens1,ens2, x4),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(extra.feature_importances_).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extra_features = None\n",
    "#rf_features = None\n",
    "#gb_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new rf\n",
      "new extra\n",
      "new gb\n",
      "Training classifier...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-9d9b9916604f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-137-2444e055325a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(x, y, y_ind)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m#         ens = np.concatenate((x1_minmax[train], ens), axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m#     pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-285bf62045e6>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[1;34m(forest, train_x, train_y, nfolds, test_x, test_y)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training classifier...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#         pred = forest.predict_proba(train_x[test])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1025\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1026\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1078\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1079\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    782\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 784\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extra, rf, knn, gb = train(\n",
    "    X,\n",
    "    Y,\n",
    "    df.IndY.loc[a].values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.98\n",
    "# 0.97\n",
    "# 0.94\n",
    "# 0.77\n",
    "\n",
    "# 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del extra_features\n",
    "# del rf_features\n",
    "# del gb_features\n",
    "# extra_features = None\n",
    "# rf_features = None\n",
    "# gb_features = None\n",
    "# features = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features -= 1\n",
    "rfe = RFE(extra)\n",
    "rfe.fit(X[extra_features].values[a], Y[a])\n",
    "extraf = pd.DataFrame(rfe.support_, columns=['vars'])\n",
    "extraf.index = pd.get_dummies(df[cols_1]).columns\n",
    "extraf.plot(kind='bar')\n",
    "extra_features = extraf.ix[extraf['vars'] == True, 'vars'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfe = RFE(rf)\n",
    "rfe.fit(X.values[a], Y[a])\n",
    "rff = pd.DataFrame(rfe.support_, columns=['vars'])\n",
    "rff.index = pd.get_dummies(df[cols_1]).columns\n",
    "rff.plot(kind='bar')\n",
    "rf_features = rff.ix[rff['vars'] == True, 'vars'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 131 elements, new values have 262 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-154-1e411e0ae112>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgb_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgbf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vars'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mgbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgb_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgbf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vars'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vars'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   2369\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2370\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2371\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2372\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2373\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/src/properties.pyx\u001b[0m in \u001b[0;36mpandas.lib.AxisProperty.__set__ (pandas/lib.c:45002)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m   2570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2571\u001b[0m             raise ValueError('Length mismatch: Expected axis has %d elements, '\n\u001b[1;32m-> 2572\u001b[1;33m                              'new values have %d elements' % (old_len, new_len))\n\u001b[0m\u001b[0;32m   2573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2574\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 131 elements, new values have 262 elements"
     ]
    }
   ],
   "source": [
    "rfe = RFE(gb)\n",
    "rfe.fit(X[gb_features].values, Y)\n",
    "gbf = pd.DataFrame(rfe.support_, columns=['vars'])\n",
    "gbf.index = pd.get_dummies(df[cols_1]).columns\n",
    "gbf.plot(kind='bar')\n",
    "gb_features = gbf.ix[gbf['vars'] == True, 'vars'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# last_valid_features = gb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# seiya = pd.DataFrame(gb.feature_importances_)\n",
    "# seiya.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# res = pred(\n",
    "#     extra,\n",
    "#     rf,\n",
    "#     knn,\n",
    "#     gb, \n",
    "#     df.loc[b]\n",
    "#           )\n",
    "# prd = clf.predict_proba(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = [.3, .3, 0, .4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voting = VotingClassifier([\n",
    "        ('extra', extra), \n",
    "        ('rf', rf), \n",
    "#         ('knn', knn), \n",
    "        ('gb', gb)\n",
    "    ],\n",
    "    weights=[\n",
    "        1,\n",
    "        1,\n",
    "#         0,\n",
    "        1.2\n",
    "    ],\n",
    "    voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voting.fit(\n",
    "    pd.get_dummies(df[cols_1].loc[a]).values,\n",
    "    Y[a]\n",
    ")\n",
    "scores = cross_validation.cross_val_score(voting, pd.get_dummies(df[cols_1].loc[b]).values,Y[b], cv=5, scoring='log_loss')\n",
    "print(\"Log loss: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prd = voting.predict_proba(pd.get_dummies(df[cols_1].loc[b]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = pred(\n",
    "    extra,\n",
    "    rf,\n",
    "    knn,\n",
    "    gb, \n",
    "    df.loc[b]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prd = (res[0] * losses[0]) + (res[1] * losses[1]) + (res[2] * losses[2]) + (res[3] * losses[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_loss(Y[b], prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.7651903888988153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_test():\n",
    "    df_test = pd.read_csv('test.csv.gz')    \n",
    "    X_test = get_vars(df_test, cols_x)\n",
    "\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = get_test()\n",
    "X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:1: FutureWarning: using '-' to provide set differences with Indexes is deprecated, use .difference()\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "missing_cols = list(gb_features - X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in missing_cols:\n",
    "    X_test[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = df.OutcomeType.unique()\n",
    "cats.sort()\n",
    "final_result = gb.predict_proba(X_test[gb_features].values)\n",
    "final_result = pd.DataFrame(final_result, columns=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cats = df.OutcomeType.unique()\n",
    "cats.sort()\n",
    "\n",
    "first, second, thirdth, fourth  = pred(extra, rf, knn, gb, X_test)\n",
    "final_result = first*one + second*two +  fourth*four # +thirdth*three\n",
    "\n",
    "# final_result = pred(extra, gb, X_test)\n",
    "final_result = pd.DataFrame(final_result, columns=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_result['Id'] = final_result.index+1\n",
    "final_result.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "t = today.strftime('%Y%m%d%H%M')\n",
    "final_result.to_csv('result_%s.csv.gz'%t, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
